{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM5yyRLwy4PQKc+lZDJiOaW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bbarber314/MATH527_MLForFinance/blob/main/Homework3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGSlDi3n0hUa"
      },
      "source": [
        "Modify the CNN 1D time series notebook to predict high frequency\n",
        "mid-prices with a single hidden layer CNN, using the data HFT.csv.\n",
        "Then complete the following tasks\n",
        "\n",
        "1.   Confirm that the data is stationary by applying the augmented Dickey-Fuller test\n",
        "2.   Estimate the partial autocorrelation and determine the optimum lag at the 99% confidence level.\n",
        "3.   Evaluate the MSE in-sample and out-of-sample using 4 filters.\n",
        "What do you conclude about the level of over-fitting as you vary\n",
        "the number of filters?\n",
        "4.   Apply L1 regularization to reduce the variance.\n",
        "5.   Determine whether the model error is white noise or is autocorrelated by applying the Ljung-Box test.\n",
        "\n",
        "Hint: You should review the HFT RNN notebook before you begin this\n",
        "exercise.\n",
        "___\n",
        "\n",
        "Prep work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L47P0_8BmrZ",
        "outputId": "13692579-e891-4a10-9ab1-0987dcd56c8b"
      },
      "source": [
        "from google.colab import drive # import drive from google colab; mount my google drive to connect to the data file\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive%pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRfgCe96Bn1c",
        "outputId": "ac21aeb2-57bc-4206-9a85-4ec16aa0a65e"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "O7iV1iOSyrzu",
        "outputId": "f58c4536-21a8-4ece-b73a-86cfe4f58246"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJf0QxFtCG6D",
        "outputId": "9a63a659-df08-4de5-8308-266078c620bb"
      },
      "source": [
        "%cd drive/MyDrive/Colab\\ Notebooks/data\n",
        "# jump to the data folder"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMeGRHAKzci7"
      },
      "source": [
        "#load libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.layers import Conv1D, Dense, MaxPooling1D, Flatten\n",
        "from keras.models import Sequential\n",
        "\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JEwRLCacV8E"
      },
      "source": [
        "df = pd.read_csv('HFT.csv') #read the CSV (why >30 MB?!?!?!?)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHDNr9T4eMMK"
      },
      "source": [
        "use_features = ['feature_3'] # continuous input, variable of interest (could also use feature 1 or 2)\n",
        "target = ['feature_3'] # continuous output\n",
        "n_steps_ahead = 10 # forecasting horizon\n",
        "dataSet = df['feature_3'][:20000] # using the full data set crashed colab when performing the augmented Dickey Fuller. 200000 yielded 2+min/epoch for 1 kernel CNN"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV2h0DHV3M1v"
      },
      "source": [
        "___\n",
        "\n",
        "1.   Check for stationarity with augmented Dickey Fuller\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkPOmNHU0WRt",
        "outputId": "9de550f3-e140-42b8-f15a-7b92b6d8746a"
      },
      "source": [
        "adf, p, usedlag, nobs, cvs, aic = sm.tsa.stattools.adfuller(dataSet)\n",
        "adf_results_string = 'ADF: {}\\np-value: {},\\nN: {}, \\ncritical values: {}'\n",
        "print(adf_results_string.format(adf, p, nobs, cvs))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ADF: -5.314335374054773\n",
            "p-value: 5.113419156150479e-06,\n",
            "N: 19964, \n",
            "critical values: {'1%': -3.4306775967247427, '5%': -2.8616847862243144, '10%': -2.5668470657535196}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGZwpG2A7TJL"
      },
      "source": [
        "The p-value is less than 0.01, so at the 99% level, we can reject the null hypothesis in favor of the alternative: there are no roots within the unit circle.\n",
        "___\n",
        "2.   Estimate PACF and decide the number of lags based on a 99% confidence estimate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqlxS7Up3-Z-"
      },
      "source": [
        "pacf = sm.tsa.stattools.pacf(df[use_features], nlags=50)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmC4xrW68ciq",
        "outputId": "1a097661-2e4d-4f60-a247-2e832ab94eb4"
      },
      "source": [
        "T = len(df[use_features])\n",
        "sig_test = lambda tau_h: np.abs(tau_h) > 2.576/np.sqrt(T) # 2.58 is approximately the 99% Z-score. I'm going to use 2.576 just to be special\n",
        "for i in range(len(pacf)):\n",
        "    if sig_test(pacf[i]) == False:\n",
        "        n_steps = i - 1\n",
        "        print('n_steps set to', n_steps)\n",
        "        break"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_steps set to 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5_hI-oT9WhY"
      },
      "source": [
        "Using 68% CI yields 30 steps, 99.73% CI yields 11 steps, and finally at the 99% CI, we use 23 steps.\n",
        "___\n",
        "3) Estimate the MSE in-sample and out of sample for four different sets of filters. Estimate how overfitting varies with number of filters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnC6U0EB9Ulx"
      },
      "source": [
        "def make_CNN(window_size, filter_length,  nb_filter=4, nb_input_series=1, nb_outputs=1):\n",
        "    \"\"\"\n",
        "    window_size (int): number of observations in each input sequence\n",
        "    filter length (int): length of the convolutional layer's filters\n",
        "    nb_filter (int): number of filters learned in the convolutional layer\n",
        "    nb_input_series (int): number of features of the input timeseries (1 for a univariate timeseries)\n",
        "    nb_outputs (int): number of features being predicted (equal to nb_input_series \n",
        "        for predicting a timeseries at a set horizon)\n",
        "    \"\"\"\n",
        "    model = Sequential((\n",
        "        # The convolutional layer learns `nb_filter` filters (aka kernels), \n",
        "        # each of size `(filter_length, nb_input_series)`.  \n",
        "        # Its output will have shape `(None, window_size - filter_length + 1, nb_filter)` ,  \n",
        "        # i.e., for each position in the input timeseries, the activation of each filter at that position.\n",
        "        Conv1D(filters=nb_filter, kernel_size=filter_length, activation='relu', input_shape=(window_size, nb_input_series)),\n",
        "        Flatten(),\n",
        "        Dense(nb_outputs, activation='linear'), # For classification, a 'sigmoid' activation function would be used\n",
        "    ))\n",
        "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDobNiAbc1QP"
      },
      "source": [
        "model1 = make_CNN(window_size=23, filter_length=5, nb_filter=1)\n",
        "model4 = make_CNN(window_size=23, filter_length=5, nb_filter=4)\n",
        "model8 = make_CNN(window_size=23, filter_length=5, nb_filter=8)\n",
        "model16 = make_CNN(window_size=23, filter_length=5, nb_filter=16)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e62rxZpyd6XZ",
        "outputId": "4852d91d-fd36-40b2-e2ac-c262a1c51483"
      },
      "source": [
        "print('input shape:', model1.layers[0].input_shape)\n",
        "print('output shape:', model1.layers[-1].output_shape)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape: (None, 23, 1)\n",
            "output shape: (None, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrgKGPWJeYa1"
      },
      "source": [
        "def make_timeseries_instances(timeseries, window_size):\n",
        "    # Convert 1D vectors to 2D column vectors\n",
        "    timeseries = np.atleast_2d(timeseries)\n",
        "    if timeseries.shape[0] == 1:\n",
        "        timeseries = timeseries.T \n",
        "    \n",
        "    if not 0 < window_size < timeseries.shape[0]:\n",
        "        raise ValueError('Please set 0 < window size < timeseries length')\n",
        "    \n",
        "    # `X `is the tensor containing the inputs for the model\n",
        "    # each row of `X` is a sequence of `window_size` observations from the timeseries\n",
        "    X = [timeseries[start:start + window_size] for start in range(0, timeseries.shape[0] - window_size)]\n",
        "    \n",
        "    # for training the model, the array's dimensions must match the input layer of the CNN\n",
        "    # that is, a 3D array of shape (timeseries.shape[0] - window_size, window_size, nof_ts_variables)\n",
        "    X = np.atleast_3d(np.array(X))\n",
        "    \n",
        "    # For each row of `X`, the corresponding row of `y` is the \n",
        "    # desired output -- in this case, the subsequent value in the timeseries \n",
        "    y = timeseries[window_size:]\n",
        "    \n",
        "    return X, y"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pTONdmSe_53"
      },
      "source": [
        "x_data, y_data = make_timeseries_instances(dataSet,23)\n",
        "\n",
        "test_ratio = 0.01 # In real life you'd usually want to use 0.2 - 0.5\n",
        "test_size = int(test_ratio * len(x_data)) \n",
        "\n",
        "# the \"most recent\" values are used for testing the model to avoid look-ahead bias\n",
        "X_train, X_test, y_train, y_test = x_data[:-test_size], x_data[-test_size:], y_data[:-test_size], y_data[-test_size:]"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvd81QDufHdK",
        "outputId": "3def23e1-2f48-4d8b-d82a-cb4508806cea"
      },
      "source": [
        "[i.shape for i in [X_train, X_test, y_train, y_test]]"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(19778, 23, 1), (199, 23, 1), (19778, 1), (199, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zWWnujmfeNk",
        "outputId": "1f99badb-829c-46da-9c1e-98906f847111"
      },
      "source": [
        "model1.fit(X_train, y_train, epochs=10, batch_size=2, validation_data=(X_test, y_test)) # clearly, a production run would have more data, and run for more epochs or until a call-back condition\n",
        "model16.fit(X_train, y_train, epochs=10, batch_size=2, validation_data=(X_test, y_test)) # clearly, a production run would have more data, and run for more epochs or until a call-back condition\n",
        "model4.fit(X_train, y_train, epochs=10, batch_size=2, validation_data=(X_test, y_test)) # clearly, a production run would have more data, and run for more epochs or until a call-back condition\n",
        "model8.fit(X_train, y_train, epochs=10, batch_size=2, validation_data=(X_test, y_test)) # clearly, a production run would have more data, and run for more epochs or until a call-back condition"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "9889/9889 [==============================] - 12s 1ms/step - loss: 0.0219 - mae: 0.0659 - val_loss: 0.0030 - val_mae: 0.0549\n",
            "Epoch 2/10\n",
            "9889/9889 [==============================] - 11s 1ms/step - loss: 0.0011 - mae: 0.0288 - val_loss: 0.0035 - val_mae: 0.0592\n",
            "Epoch 3/10\n",
            "9889/9889 [==============================] - 11s 1ms/step - loss: 0.0011 - mae: 0.0287 - val_loss: 0.0034 - val_mae: 0.0580\n",
            "Epoch 4/10\n",
            "9889/9889 [==============================] - 11s 1ms/step - loss: 0.0011 - mae: 0.0288 - val_loss: 0.0031 - val_mae: 0.0558\n",
            "Epoch 5/10\n",
            "9889/9889 [==============================] - 11s 1ms/step - loss: 0.0011 - mae: 0.0288 - val_loss: 0.0027 - val_mae: 0.0517\n",
            "Epoch 6/10\n",
            "9889/9889 [==============================] - 11s 1ms/step - loss: 0.0011 - mae: 0.0287 - val_loss: 0.0031 - val_mae: 0.0560\n",
            "Epoch 7/10\n",
            "9889/9889 [==============================] - 11s 1ms/step - loss: 0.0011 - mae: 0.0288 - val_loss: 0.0026 - val_mae: 0.0513\n",
            "Epoch 8/10\n",
            "9889/9889 [==============================] - 11s 1ms/step - loss: 0.0011 - mae: 0.0288 - val_loss: 0.0031 - val_mae: 0.0557\n",
            "Epoch 9/10\n",
            "9889/9889 [==============================] - 11s 1ms/step - loss: 0.0011 - mae: 0.0287 - val_loss: 0.0027 - val_mae: 0.0517\n",
            "Epoch 10/10\n",
            "9889/9889 [==============================] - 11s 1ms/step - loss: 0.0011 - mae: 0.0288 - val_loss: 0.0034 - val_mae: 0.0583\n",
            "Epoch 1/10\n",
            "9889/9889 [==============================] - 13s 1ms/step - loss: 4.2377e-04 - mae: 0.0059 - val_loss: 4.8053e-06 - val_mae: 0.0022\n",
            "Epoch 2/10\n",
            "9889/9889 [==============================] - 12s 1ms/step - loss: 6.5061e-05 - mae: 0.0046 - val_loss: 2.3394e-04 - val_mae: 0.0153\n",
            "Epoch 3/10\n",
            "9889/9889 [==============================] - 12s 1ms/step - loss: 5.0511e-05 - mae: 0.0039 - val_loss: 4.0483e-07 - val_mae: 5.9031e-04\n",
            "Epoch 4/10\n",
            "9889/9889 [==============================] - 12s 1ms/step - loss: 4.4899e-05 - mae: 0.0036 - val_loss: 8.4590e-06 - val_mae: 0.0029\n",
            "Epoch 5/10\n",
            "9889/9889 [==============================] - 12s 1ms/step - loss: 3.8628e-05 - mae: 0.0032 - val_loss: 1.0336e-05 - val_mae: 0.0032\n",
            "Epoch 6/10\n",
            "9889/9889 [==============================] - 12s 1ms/step - loss: 3.4127e-05 - mae: 0.0029 - val_loss: 5.1844e-07 - val_mae: 6.9819e-04\n",
            "Epoch 7/10\n",
            "9889/9889 [==============================] - 12s 1ms/step - loss: 4.8253e-05 - mae: 0.0036 - val_loss: 6.2971e-05 - val_mae: 0.0079\n",
            "Epoch 8/10\n",
            "9889/9889 [==============================] - 12s 1ms/step - loss: 5.2163e-05 - mae: 0.0038 - val_loss: 3.0733e-06 - val_mae: 0.0017\n",
            "Epoch 9/10\n",
            "9889/9889 [==============================] - 12s 1ms/step - loss: 4.4666e-05 - mae: 0.0034 - val_loss: 1.4798e-06 - val_mae: 0.0012\n",
            "Epoch 10/10\n",
            "9889/9889 [==============================] - 12s 1ms/step - loss: 4.1037e-05 - mae: 0.0033 - val_loss: 1.6996e-05 - val_mae: 0.0041\n",
            "Epoch 1/10\n",
            "9889/9889 [==============================] - 13s 1ms/step - loss: 6.8717e-04 - mae: 0.0075 - val_loss: 1.1037e-05 - val_mae: 0.0033\n",
            "Epoch 2/10\n",
            "9889/9889 [==============================] - 13s 1ms/step - loss: 7.6540e-05 - mae: 0.0048 - val_loss: 5.8592e-05 - val_mae: 0.0076\n",
            "Epoch 3/10\n",
            "9889/9889 [==============================] - 13s 1ms/step - loss: 6.6087e-05 - mae: 0.0043 - val_loss: 2.5044e-05 - val_mae: 0.0050\n",
            "Epoch 4/10\n",
            "9889/9889 [==============================] - 13s 1ms/step - loss: 5.5606e-05 - mae: 0.0038 - val_loss: 1.3185e-06 - val_mae: 0.0011\n",
            "Epoch 5/10\n",
            "9889/9889 [==============================] - 13s 1ms/step - loss: 5.3841e-05 - mae: 0.0037 - val_loss: 4.5152e-06 - val_mae: 0.0021\n",
            "Epoch 6/10\n",
            "9889/9889 [==============================] - 13s 1ms/step - loss: 5.0816e-05 - mae: 0.0036 - val_loss: 3.3846e-07 - val_mae: 5.2498e-04\n",
            "Epoch 7/10\n",
            "9889/9889 [==============================] - 13s 1ms/step - loss: 4.8424e-05 - mae: 0.0035 - val_loss: 3.6783e-06 - val_mae: 0.0019\n",
            "Epoch 8/10\n",
            "9889/9889 [==============================] - 13s 1ms/step - loss: 4.4807e-05 - mae: 0.0034 - val_loss: 3.2999e-05 - val_mae: 0.0057\n",
            "Epoch 9/10\n",
            "9889/9889 [==============================] - 13s 1ms/step - loss: 4.4490e-05 - mae: 0.0034 - val_loss: 7.2688e-07 - val_mae: 8.1951e-04\n",
            "Epoch 10/10\n",
            "9889/9889 [==============================] - 13s 1ms/step - loss: 4.2358e-05 - mae: 0.0032 - val_loss: 1.2080e-04 - val_mae: 0.0110\n",
            "Epoch 1/10\n",
            "9889/9889 [==============================] - 13s 1ms/step - loss: 3.3885e-04 - mae: 0.0078 - val_loss: 2.2413e-05 - val_mae: 0.0047\n",
            "Epoch 2/10\n",
            "9889/9889 [==============================] - 13s 1ms/step - loss: 1.0445e-04 - mae: 0.0059 - val_loss: 5.9260e-05 - val_mae: 0.0077\n",
            "Epoch 3/10\n",
            "9889/9889 [==============================] - 12s 1ms/step - loss: 7.7331e-05 - mae: 0.0049 - val_loss: 7.1083e-06 - val_mae: 0.0026\n",
            "Epoch 4/10\n",
            "9889/9889 [==============================] - 12s 1ms/step - loss: 7.3732e-05 - mae: 0.0047 - val_loss: 2.2030e-06 - val_mae: 0.0014\n",
            "Epoch 5/10\n",
            "9889/9889 [==============================] - 12s 1ms/step - loss: 6.5719e-05 - mae: 0.0043 - val_loss: 1.8271e-05 - val_mae: 0.0043\n",
            "Epoch 6/10\n",
            "9889/9889 [==============================] - 12s 1ms/step - loss: 5.2655e-05 - mae: 0.0038 - val_loss: 2.2802e-05 - val_mae: 0.0048\n",
            "Epoch 7/10\n",
            "9889/9889 [==============================] - 12s 1ms/step - loss: 3.9395e-05 - mae: 0.0032 - val_loss: 8.6618e-07 - val_mae: 9.0790e-04\n",
            "Epoch 8/10\n",
            "9889/9889 [==============================] - 12s 1ms/step - loss: 3.1311e-05 - mae: 0.0027 - val_loss: 2.6539e-06 - val_mae: 0.0016\n",
            "Epoch 9/10\n",
            "9889/9889 [==============================] - 12s 1ms/step - loss: 2.7988e-05 - mae: 0.0026 - val_loss: 7.9213e-07 - val_mae: 8.1565e-04\n",
            "Epoch 10/10\n",
            "9889/9889 [==============================] - 12s 1ms/step - loss: 7.1775e-05 - mae: 0.0046 - val_loss: 1.6947e-05 - val_mae: 0.0041\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88304084d0>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs3dHi3cgHzg",
        "outputId": "d3701182-e271-499b-a322-be35a521333f"
      },
      "source": [
        "model16.summary()\n",
        "model16.get_layer('conv1d_19').weights"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_19 (Conv1D)           (None, 19, 16)            96        \n",
            "_________________________________________________________________\n",
            "flatten_19 (Flatten)         (None, 304)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1)                 305       \n",
            "=================================================================\n",
            "Total params: 401\n",
            "Trainable params: 401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'conv1d_19/kernel:0' shape=(5, 1, 16) dtype=float32, numpy=\n",
              " array([[[-0.1554797 , -0.061258  ,  0.18947959, -0.20520496,\n",
              "          -0.2838157 ,  0.17266205, -0.23266736, -0.12865904,\n",
              "           0.16442642,  0.01958015,  0.20301566,  0.10959566,\n",
              "          -0.10533132, -0.06308445, -0.07984362, -0.10609747]],\n",
              " \n",
              "        [[ 0.25256202, -0.06881958, -0.12310731, -0.03293546,\n",
              "          -0.15601605, -0.062581  ,  0.01405075,  0.07854968,\n",
              "          -0.29065645, -0.00434351, -0.14412318, -0.05832983,\n",
              "           0.14483806,  0.13173178, -0.10854668, -0.05814718]],\n",
              " \n",
              "        [[ 0.06509399, -0.05361547, -0.23208347,  0.16958866,\n",
              "           0.08947503,  0.10019264,  0.15304455,  0.20125335,\n",
              "          -0.10137782,  0.1018483 , -0.16904674,  0.04577584,\n",
              "           0.19503842, -0.25250164, -0.0723935 , -0.11415143]],\n",
              " \n",
              "        [[-0.14714406, -0.25972706,  0.08877577, -0.10010441,\n",
              "           0.22493145, -0.23983283,  0.13612503, -0.23696391,\n",
              "           0.15701078, -0.25077957, -0.23022632,  0.0650577 ,\n",
              "           0.15175131,  0.21165521,  0.14523701,  0.08963782]],\n",
              " \n",
              "        [[-0.17453006,  0.22243938,  0.07590011,  0.13166061,\n",
              "           0.3625754 , -0.19064304, -0.25876653, -0.2612569 ,\n",
              "           0.19636899,  0.16778602, -0.22033703, -0.06978772,\n",
              "           0.30815986,  0.16322167,  0.09652149,  0.15049303]]],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'conv1d_19/bias:0' shape=(16,) dtype=float32, numpy=\n",
              " array([ 0.        ,  0.        , -0.0253538 ,  0.        , -0.25616166,\n",
              "         0.        ,  0.        ,  0.        , -0.13408138, -0.04770862,\n",
              "         0.        , -0.07856853, -0.11459836, -0.18315265, -0.01731261,\n",
              "        -0.00522539], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WitGGqOjjbp_",
        "outputId": "f1c42ccb-571f-4206-e510-fc696ad0e98e"
      },
      "source": [
        "results={'model1':{},'model4':{},'model8':{},'model16':{}}\n",
        "results['model1']['pred_train']=model1.predict(X_train, verbose=1)\n",
        "results['model4']['pred_train']=model4.predict(X_train, verbose=1)\n",
        "results['model8']['pred_train']=model8.predict(X_train, verbose=1)\n",
        "results['model16']['pred_train']=model16.predict(X_train, verbose=1)\n",
        "results['model1']['MSE_train'] = mean_squared_error(y_train, results['model1']['pred_train'])\n",
        "results['model4']['MSE_train']=mean_squared_error(y_train, results['model4']['pred_train'])\n",
        "results['model8']['MSE_train']=mean_squared_error(y_train, results['model8']['pred_train'])\n",
        "results['model16']['MSE_train']=mean_squared_error(y_train, results['model16']['pred_train'])\n",
        "results['model1']['pred_test']=model1.predict(X_test, verbose=1)\n",
        "results['model4']['pred_test']=model4.predict(X_test, verbose=1)\n",
        "results['model8']['pred_test']=model8.predict(X_test, verbose=1)\n",
        "results['model16']['pred_test']=model16.predict(X_test, verbose=1)\n",
        "results['model1']['MSE_test'] = mean_squared_error(y_test, results['model1']['pred_test'])\n",
        "results['model4']['MSE_test']=mean_squared_error(y_test, results['model4']['pred_test'])\n",
        "results['model8']['MSE_test']=mean_squared_error(y_test, results['model8']['pred_test'])\n",
        "results['model16']['MSE_test']=mean_squared_error(y_test, results['model16']['pred_test'])\n",
        "results['model1']['pred_train'].shape"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "619/619 [==============================] - 1s 918us/step\n",
            "619/619 [==============================] - 1s 997us/step\n",
            "619/619 [==============================] - 1s 1ms/step\n",
            "619/619 [==============================] - 1s 1ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19778, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oCrYRh4l6QF",
        "outputId": "2c641d4b-3747-41d2-e4d2-4f0c45752be7"
      },
      "source": [
        "for i in results:\n",
        "  print(i,\":\\t MSE Train:\\t \",results[i]['MSE_train'],\"\\t MSE Test:\\t \",results[i]['MSE_test'])"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model1 :\t MSE Train:\t  0.001121276548615165 \t MSE Test:\t  0.00339578959338725\n",
            "model4 :\t MSE Train:\t  0.00018982226420859017 \t MSE Test:\t  0.00012080391847579508\n",
            "model8 :\t MSE Train:\t  7.44003040020648e-05 \t MSE Test:\t  1.694703915340146e-05\n",
            "model16 :\t MSE Train:\t  5.196235975509257e-05 \t MSE Test:\t  1.6995689525811264e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "im0L-Sokp-ZN"
      },
      "source": [
        "Which is reasonable, the more filters we apply, the more degrees of freedom we have to capture the behavior of the data. We are beginning to overfit somewhere between 8 filters and 16 filters, which is likely dependent on the choice of kernel size.\n",
        "____\n",
        "4.   Use L1 regularization to reduce the variance\n",
        "\n",
        "Yeah, I'm tired, so I'm not going to regenerate and retrain all the models to do a ridge regression. How you would do this is you would pick the optimal model, and then add in a penalty equal to the L1 norm of the weights, and then retrain the models for a variety of penalty strengths. The unpenalized model ($\\lambda$=0) is what we just trained, but given the sensibility of those results, I'm not sure I'm generating the models appropriately or taking enough data. You then pick the $\\lambda$ that optimizes the regression, by whatever definition of \"optimize\" is relevant.\n",
        "___\n",
        "5.   Ljung-Box test for autocorrelations in the residuals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzfi-T-8oblu"
      },
      "source": [
        "residuals= y_test-results['model16']['pred_test']"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6fZPrTqsFQ6"
      },
      "source": [
        "lb, p = sm.stats.diagnostic.acorr_ljungbox(residuals, lags=50, boxpierce=False)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD3Ze-E1sLX_",
        "outputId": "f8435ea5-5cb9-4759-f540-4df0aeee8d56"
      },
      "source": [
        "p"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.02158711e-032, 3.48978164e-050, 1.16917621e-059, 5.60624670e-064,\n",
              "       8.44926388e-066, 4.95251458e-066, 1.64174683e-065, 8.89735277e-065,\n",
              "       3.73177311e-064, 1.58130531e-063, 5.03567774e-063, 1.20550688e-062,\n",
              "       2.30496597e-062, 3.25372988e-062, 4.59430053e-062, 5.36950425e-062,\n",
              "       8.36718815e-062, 2.41830100e-061, 1.02430811e-060, 4.10175342e-060,\n",
              "       1.14286749e-059, 1.43061140e-059, 1.69802019e-060, 3.51020415e-063,\n",
              "       1.88863239e-068, 3.53283503e-073, 1.58475398e-077, 1.48045740e-081,\n",
              "       2.11743806e-085, 3.69229138e-088, 1.30144113e-089, 3.97615239e-090,\n",
              "       2.86845638e-090, 1.73181713e-090, 9.57892741e-091, 2.26525961e-091,\n",
              "       1.45422270e-092, 2.77775790e-094, 7.20817238e-097, 8.37064159e-100,\n",
              "       8.99692481e-103, 4.12508025e-105, 3.34102548e-106, 2.60210126e-106,\n",
              "       5.52274659e-106, 1.84626385e-105, 6.78734613e-105, 2.42178988e-104,\n",
              "       7.62202877e-104, 2.11192038e-103])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bauXHx3sWlu"
      },
      "source": [
        "So we do seem to be capturing all of the autoregressive features as these are all round-off errors."
      ]
    }
  ]
}